{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning pre-trained VGGFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1dcyuqvEf2ScWk5I3Mjb5HN6PDpSQbEAQ",
      "authorship_tag": "ABX9TyPb6mlhSnK+Kd3PS67XjOUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgbartnik/comparison_between_visual_saliency_maps_of_CNN_and_those_of_human_beings/blob/master/Finetuning_pre_trained_VGGFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or3bEP9Pdv5j",
        "colab_type": "text"
      },
      "source": [
        "# A Comparison between Visual Saliency Maps of Convolutional Neural Networks and those of Human Beings: A Study on Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iTPZ6q7d_mq",
        "colab_type": "text"
      },
      "source": [
        "**Overview**\n",
        "-----------------\n",
        "\n",
        "This notebook conains the code to fine-tune the CNN used in this master thesis. \n",
        "\n",
        "In this master thesis the feature extractor from a pre-trained Visual Geometry Group Face model (VGG Face model) was used. It was developed by Parkhi, Vedaldi, and Zisserman (2015) for recognizing faces of 2,622 celebrities. It was favoured over other widely used pre-trained models like ImageNet oder AlexNet because it was trained exclusively on faces.\n",
        "\n",
        "Up to this point, there is no public available Keras implementation with the respective pre-trained weights for the new VGG-Face2 dataset. Therefore, this master thesis uses a Keras implementation for the VGG-Face model trained on the original dataset.\n",
        "\n",
        "The pre-trained VGG Face model, is based on the VGG16 architecture and this master thesis is using weights from the keras-vggface, package implemented with the deep learning library Keras (version 2.2.5) and a Tensorflow (version 1.15.0) backend. The network is fine tuned with the training set in the notebook described above. Only the weights of the fully connected layers *fc6* and *fc7* with their respective 512 neurons were retrained, as well as *fc8* with seven neurons that classified the images to one of the seven expressions. \n",
        "\n",
        "For training, the following hyperparameters were used: The **ADAM optimizer** with a learning rate of *1e-5* and a decay of *1e-6*, as loss function **categorical crossentropy** and *20* epochs with *19* training steps and *5* validation steps for fine tuning the CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GecYFttMeq4W",
        "colab_type": "text"
      },
      "source": [
        "# Fine tuning the pretrained VGG Face model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyYBuWdnKqkk",
        "colab_type": "text"
      },
      "source": [
        "## Loading packages for the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdu8FHQ0Jc6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "52f6a428-0de9-4a94-cb0a-7976f64b93a3"
      },
      "source": [
        "# Loading required packages \n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from keras.engine import  Model\n",
        "from keras.layers import Input, Flatten, Dense, AveragePooling2D \n",
        "\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX1-N1G8Jr2-",
        "colab_type": "text"
      },
      "source": [
        "Installing the library containing the pretrained VGG Face Keras implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSETDo8RJzoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "9ee06820-5c30-4e52-d9a5-4f8fe25bfc51"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-0fboi7j7\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-0fboi7j7\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vggface==0.6) (1.1.0)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8311 sha256=b404484e6bceddcd690741fabdb171ddc36a5d5c43d0076a751a4310a40d6b9d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y3loz0vi/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMQz0E1_J4lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the VGGFace library\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPBavZ0vKn-F",
        "colab_type": "text"
      },
      "source": [
        "## Reading in the preprocessed train- and testdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBQosjIBKDu-",
        "colab_type": "text"
      },
      "source": [
        "If not running the complete notebook you can read in preprocessed Train-and Testdata using the saved csv-files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mw4qfTBKRT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv('/content/gdrive/My Drive/Thesis/Train_Test_CSV/test_data.csv')\n",
        "train_data = pd.read_csv('/content/gdrive/My Drive/Thesis/Train_Test_CSV/train_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgcSzslnK96E",
        "colab_type": "text"
      },
      "source": [
        "Rename the **Image** colum to not show the full path but only the image name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-vjpJ0JK6LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train = train_data[\"Image\"].str.split(\"Train/\", n = 1, expand = True)\n",
        "train_data['Image'] = new_train[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4VXa3j8K9O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_test = test_data[\"Image\"].str.split(\"Test/\", n = 1, expand = True)\n",
        "test_data['Image'] = new_test[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvj_580_LK8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the new csv files with the split Image column\n",
        "os.chdir(\"/content/gdrive/My Drive/Thesis/Train_Test_CSV/\")\n",
        "train_data.to_csv(\"train_data_2.csv\", sep=',', encoding='utf-8')\n",
        "test_data.to_csv(\"test_data_2.csv\", sep=',', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLuOPBtlL6vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading in the new dataframes.\n",
        "test_data = pd.read_csv('/content/gdrive/My Drive/Thesis/Train_Test_CSV/test_data_2.csv')\n",
        "train_data = pd.read_csv('/content/gdrive/My Drive/Thesis/Train_Test_CSV/train_data_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAxRVDN9MUEt",
        "colab_type": "text"
      },
      "source": [
        "## Image Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyevgih5MdJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                           validation_split=0.2,\n",
        "                           width_shift_range=0.2,\n",
        "                           height_shift_range=0.2,\n",
        "                           shear_range=0.2,\n",
        "                           zoom_range=0.2,\n",
        "                           horizontal_flip=True,\n",
        "                           brightness_range = [0.5, 1.5],\n",
        "                           fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbpm5VFWMnS2",
        "colab_type": "text"
      },
      "source": [
        "Rotation another classic augmentation technique is not used because when rotating faces the human recognition performance drops. Could be checked in different studys how CNNs are effected by rotating faces. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dXBi9OyM3Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1b030b3e-beed-4457-8f00-2cfc7101e645"
      },
      "source": [
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = train_data,\n",
        "    directory = \"/content/gdrive/My Drive/Thesis/Train\",\n",
        "    x_col=\"Image\",\n",
        "    y_col=\"label\",\n",
        "    subset=\"training\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(224,224))\n",
        "\n",
        "valid_generator = datagen.flow_from_dataframe(\n",
        "    dataframe = train_data,\n",
        "    directory = \"/content/gdrive/My Drive/Thesis/Train\",\n",
        "    x_col=\"Image\",\n",
        "    y_col=\"label\",\n",
        "    subset=\"validation\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 603 validated image filenames belonging to 7 classes.\n",
            "Found 150 validated image filenames belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p2RxqOBNGtd",
        "colab_type": "text"
      },
      "source": [
        "## Model definition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amh-_zYUNPrs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3b7ac037-b86d-453e-b64f-a7db140f50cd"
      },
      "source": [
        "modelname = \"FER_VGGFace_finetune\"\n",
        "nb_class = 7   # number of classes. \n",
        "hidden_dim = 512\n",
        "\n",
        "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
        "last_layer = vgg_model.get_layer('pool5').output\n",
        "x = Flatten(name='flatten')(last_layer)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
        "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
        "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
        "custom_vgg_model = Model(vgg_model.input, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58916864/58909280 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL7OCIZzNgRD",
        "colab_type": "text"
      },
      "source": [
        "**Overview over the used VGG Face model for the finetuning**\n",
        "\n",
        "**fc6, fc7** and **fc8** are finetuned. \n",
        "\n",
        "This is called transfer learning. Then the VGG Face model is trained on face recognition, recognizing the faces of 2.622 celebreties. In this work the first part of the CNN the feature extractor is kept and the second part the classifier is retrained to classify facial expressions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6cmDnLBNcko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "f25b7ddb-cd30-42cb-8337-7a8ce9b92ca3"
      },
      "source": [
        "custom_vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc6 (Dense)                  (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "fc7 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "fc8 (Dense)                  (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 27,826,503\n",
            "Trainable params: 27,826,503\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvcEiTj6QQhR",
        "colab_type": "text"
      },
      "source": [
        "**Setting the Hyperparameters:**\n",
        "\n",
        "For training the hyperparameters were choosen as followed. The ADAM optimizer was used with a learning rate of 1e-5 and a decay of 1e-6, categorical crossentropy was used as loss function. The network was fine-tuned for 20 epochs with 19 steps each and 5 validation steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBj8fACDQTDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optimizers.Adam(lr=1e-5, decay=1e-6)\n",
        "  \n",
        "custom_vgg_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0R6o2NzR-Ra",
        "colab_type": "text"
      },
      "source": [
        "**Creating the Callbacks for the training process:**\n",
        "\n",
        "Each epoch the model is saved to the folder **Saved_models**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfQLzgOeSGeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Thesis/Saved_models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IrUfuh_SZSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQb5sv_ESd9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "outputId": "5c75a032-cad0-4f0a-f8af-4435010afd36"
      },
      "source": [
        "history = custom_vgg_model.fit_generator(train_generator,\n",
        "                    steps_per_epoch = 19,\n",
        "                    epochs = 20,\n",
        "                    validation_data = valid_generator,\n",
        "                    validation_steps = 5,\n",
        "                    callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 1225s 64s/step - loss: 1.9370 - acc: 0.2047 - val_loss: 1.9196 - val_acc: 0.2467\n",
            "\n",
            "Epoch 00001: saving model to saved-model-01-0.25.hdf5\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 1215s 64s/step - loss: 1.8985 - acc: 0.3207 - val_loss: 1.8345 - val_acc: 0.4267\n",
            "\n",
            "Epoch 00002: saving model to saved-model-02-0.43.hdf5\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 1205s 63s/step - loss: 1.6224 - acc: 0.5268 - val_loss: 1.2063 - val_acc: 0.6067\n",
            "\n",
            "Epoch 00003: saving model to saved-model-03-0.61.hdf5\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 1209s 64s/step - loss: 0.9845 - acc: 0.6546 - val_loss: 1.0359 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00004: saving model to saved-model-04-0.60.hdf5\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 1219s 64s/step - loss: 0.7301 - acc: 0.7506 - val_loss: 0.6831 - val_acc: 0.7867\n",
            "\n",
            "Epoch 00005: saving model to saved-model-05-0.79.hdf5\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 1211s 64s/step - loss: 0.5052 - acc: 0.8241 - val_loss: 0.5508 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00006: saving model to saved-model-06-0.82.hdf5\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 1205s 63s/step - loss: 0.5563 - acc: 0.8324 - val_loss: 0.5761 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00007: saving model to saved-model-07-0.82.hdf5\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 1202s 63s/step - loss: 0.3951 - acc: 0.8883 - val_loss: 0.4688 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00008: saving model to saved-model-08-0.84.hdf5\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 1202s 63s/step - loss: 0.3408 - acc: 0.8935 - val_loss: 0.6127 - val_acc: 0.7867\n",
            "\n",
            "Epoch 00009: saving model to saved-model-09-0.79.hdf5\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 1203s 63s/step - loss: 0.2958 - acc: 0.9109 - val_loss: 0.5544 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00010: saving model to saved-model-10-0.83.hdf5\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 1205s 63s/step - loss: 0.3400 - acc: 0.8902 - val_loss: 0.4621 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00011: saving model to saved-model-11-0.86.hdf5\n",
            "Epoch 12/20\n",
            "16/19 [========================>.....] - ETA: 2:57 - loss: 0.2927 - acc: 0.8938"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwpoYO3DBbii",
        "colab_type": "text"
      },
      "source": [
        "-------------------------\n",
        "\n",
        "This code was used to fine-tune the pre-trained VGG Face Model. Because the code was rerun, the displayed outputs above are not matching exactly the ones in the master thesis. To replicate the exact results the training history (*historyKDEF_model_100*) and the saved weights of the trained model (*saved-model-16-0.93.hdf5*) can be found in the public [GDrive folder](https://drive.google.com/drive/folders/10iGq7jdLaIG-VZZ1OGK6EleTJlkfq0x_?usp=sharing). \n",
        "\n"
      ]
    }
  ]
}